{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w73w6syF2by"
      },
      "source": [
        "###**Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "37LK7Be5F1-9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys, copy\n",
        "from itertools import product\n",
        "from collections import defaultdict\n",
        "from rdkit.Chem.rdmolfiles import MolFromSmiles\n",
        "from rdkit.Chem.Graphs import CharacteristicPolynomial\n",
        "from rdkit.Chem.rdmolops import AddHs, GetAdjacencyMatrix, GetDistanceMatrix\n",
        "\n",
        "#-------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RWd3A0BFpHQ"
      },
      "source": [
        "###**MMLToolkit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T_Ok2m0aFoHE"
      },
      "outputs": [],
      "source": [
        "\n",
        "def mae_power_error(y_true, y_HfP, y_MW, y_VMW, y_pred, save=False):\n",
        "  return np.mean(np.abs((y_true-((y_pred-y_HfP)/y_MW*y_VMW))))\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "# MMLtoolkit.CV_tools.py\n",
        "def mean_absolute_percentage_error(y_true, y_pred, save=False):\n",
        "  return np.mean(np.abs((y_true-y_pred)/(y_true)))*100\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred, save=False):\n",
        "  return np.mean(np.abs((y_true-y_pred)))\n",
        "\n",
        "def neg_mean_absolute_error(y_true, y_pred, save=False):\n",
        "  return -1*np.mean(np.abs((y_true-y_pred)))\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "# MMLtoolkit.featurizations.py\n",
        "atom_num_dict = {'C':6,'N':7,'O':8,'H':1,'F':9, 'Cl': 17, 'S': 16 }\n",
        "\n",
        "def bag_of_bonds(filename_list, verbose=False):\n",
        "  num_mols = len(filename_list)\n",
        "  # initialize empty dictionary for storing each bag as a list\n",
        "  atom_types = ['C', 'N', 'O', 'F', 'H']\n",
        "  num_atom_types = len(atom_types); empty_BoB_dict = {}\n",
        "  # initialize empty list\n",
        "  for atom_type in atom_types : empty_BoB_dict[atom_type] = []\n",
        "  for i in range(num_atom_types):\n",
        "    for j in range(i,num_atom_types): empty_BoB_dict[atom_types[i]+atom_types[j]]=[]\n",
        "  # fill dicts in dict list\n",
        "  BoB_dict_list = []\n",
        "  if (verbose): print(\"creating intial BoBs\")\n",
        "  for m, filename in enumerate(filename_list):\n",
        "    xyzfile = open(filename, 'r'); num_atoms_file = int(xyzfile.readline())\n",
        "    xyzfile.close(); Cmat = np.zeros((num_atoms_file,num_atoms_file))\n",
        "    chargearray = np.zeros((num_atoms_file, 1))\n",
        "    xyzmatrix = np.loadtxt(filename, skiprows=2, usecols=[1,2,3])\n",
        "    atom_symbols = np.loadtxt(filename, skiprows=2, dtype=bytes, usecols=[0])\n",
        "    atom_symbols = [symbol.decode('utf-8') for symbol in atom_symbols]\n",
        "    chargearray = [atom_num_dict[symbol] for symbol in atom_symbols]\n",
        "    BoB_dict = copy.deepcopy(empty_BoB_dict)\n",
        "    # populate BoB dict\n",
        "    for i in range(num_atoms_file):\n",
        "      for j in range(i, num_atoms_file):\n",
        "        # concactenate to list\n",
        "        if i == j : BoB_dict[atom_symbols[i]] += [0.5*chargearray[i]**2.4]\n",
        "        else :\n",
        "          dict_key = atom_symbols[i]+atom_symbols[j]\n",
        "          dist=np.linalg.norm(xyzmatrix[i,:] - xyzmatrix[j,:])\n",
        "          CM_term = chargearray[i]*chargearray[j]/dist\n",
        "          # concactenate to list\n",
        "          try : BoB_dict[dict_key] += [CM_term]\n",
        "          except KeyError :\n",
        "            dict_key = atom_symbols[j]+atom_symbols[i]\n",
        "            BoB_dict[dict_key] += [CM_term]\n",
        "    BoB_dict_list += [BoB_dict]\n",
        "  '''\n",
        "  tricky processing stage - zero pad all bags so they all have the same length\n",
        "  and then cocatenate all bags into a feature vector for each molecule\n",
        "  For each key in the dict, zero pad the bags, and do this for all molecules\n",
        "  also sum these up to get the total length of the final feature vector\n",
        "  '''\n",
        "  feature_vect_length = 0\n",
        "  if (verbose): print(\"finding max length of each bag and padding\")\n",
        "  for key in BoB_dict_list[0].keys():\n",
        "    max_length = 0\n",
        "    # find max bag length\n",
        "    for i in range(num_mols):\n",
        "      length = len(BoB_dict_list[i][key])\n",
        "      if (length > max_length): max_length = length\n",
        "    if (verbose): print(f'max length of {key} is {max_length}')\n",
        "    # zero pad each bag\n",
        "    for i in range(num_mols):\n",
        "      pad_width = max_length - len(BoB_dict_list[i][key])\n",
        "      BoB_dict_list[i][key] = BoB_dict_list[i][key]+[0]*pad_width\n",
        "    feature_vect_length += max_length\n",
        "  # initialize Numpy feature vector array\n",
        "  X_BoB = np.zeros((num_mols, feature_vect_length))\n",
        "  # concatenation of all bags\n",
        "  if (verbose): print(\"concatenating the bags\")\n",
        "  for m in range(num_mols):\n",
        "    featvec = []\n",
        "    for key in BoB_dict_list[m].keys():\n",
        "      featvec += sorted(BoB_dict_list[m][key], reverse=True)\n",
        "    X_BoB[m,:] = np.array(featvec)\n",
        "  # concatenate feature names\n",
        "  feature_names = []\n",
        "  for key in BoB_dict_list[0].keys():\n",
        "    for element in BoB_dict_list[0][key]: feature_names += [key]\n",
        "  return feature_names, X_BoB\n",
        "\n",
        "def summed_bag_of_bonds(filename):\n",
        "  \"\"\"\n",
        "  Based on Hansen, et al., The Journal of Physical Chemistry Letters 2015 6 (12), 2326-2331\n",
        "  DOI: 10.1021/acs.jpclett.5b00831, URL: http://pubs.acs.org/doi/abs/10.1021/acs.jpclett.5b00831\n",
        "    However, the Coulomb matrix terms for each atom pair (C-C, C-N, C-O, etc) are **summed** together.\n",
        "    The diagonal terms of the Coulomb matrix are concatenated with the resulting vector.\n",
        "    So the resulting feature vector for each molecule is a vector of length\n",
        "    (num_atom_pair_types + num_atom_types). This is different than the original BoB, which maintains each\n",
        "    CM entry in the feature vector.\n",
        "  Args:\n",
        "    filename : (string) the .xyz input filename for the molecule\n",
        "  Returns:\n",
        "    (feature_names, BoB_list) as lists\n",
        "  \"\"\"\n",
        "  xyzfile = open(filename, 'r'); num_atoms_file = int(xyzfile.readline())\n",
        "  xyzfile.close(); Cmat = np.zeros((num_atoms_file,num_atoms_file))\n",
        "  chargearray = np.zeros((num_atoms_file, 1))\n",
        "  xyzmatrix = np.loadtxt(filename, skiprows=2, usecols=[1,2,3])\n",
        "  atom_symbols = np.loadtxt(filename, skiprows=2, dtype=bytes, usecols=[0])\n",
        "  atom_symbols = [symbol.decode('utf-8') for symbol in atom_symbols]\n",
        "  chargearray = [atom_num_dict[symbol] for symbol in atom_symbols]\n",
        "  # Initialize dictionary for storing each bag\n",
        "  atom_types = ['C', 'N', 'O', 'F', 'H']\n",
        "  num_atom_types = len(atom_types); BoB_dict = {}\n",
        "  for atom_type in atom_types: BoB_dict[atom_type] = 0\n",
        "  for i in range(num_atom_types):\n",
        "    for j in range(i,num_atom_types): BoB_dict[atom_types[i]+atom_types[j]] = 0\n",
        "  # Populate BoB dict\n",
        "  for i in range(num_atoms_file):\n",
        "    for j in range(i, num_atoms_file):\n",
        "      if i == j : BoB_dict[atom_symbols[i]] += 0.5*chargearray[i]**2.4\n",
        "      else :\n",
        "        dict_key = atom_symbols[i]+atom_symbols[j]\n",
        "        dist=np.linalg.norm(xyzmatrix[i,:] - xyzmatrix[j,:])\n",
        "        CM_term = chargearray[i]*chargearray[j]/dist\n",
        "        try : BoB_dict[dict_key] += CM_term\n",
        "        except KeyError :\n",
        "          dict_key = atom_symbols[j]+atom_symbols[i]\n",
        "          BoB_dict[dict_key] += CM_term\n",
        "  # Process into list\n",
        "  feature_names = list(BoB_dict.keys())\n",
        "  BoB_list = [BoB_dict[feature] for feature in feature_names]\n",
        "  return feature_names, BoB_list\n",
        "\n",
        "def coulombmat_eigenvalues_from_coords(atom_types, coords, padded_size):\n",
        "  \"\"\"\n",
        "  returns sorted Coulomb matrix eigenvalues\n",
        "  Args:\n",
        "    atom_types : a list of atom types (single characters)\n",
        "    coords : the coords as a (num_atoms x 3) numpy array\n",
        "    padded_size : the number of atoms in the biggest molecule to be considered\n",
        "                  anything smaller will have zeros padded to the eigenvalue list\n",
        "  Returns:\n",
        "    Cmat_eigenvalues : as a Numpy array\n",
        "  \"\"\"\n",
        "  atom_num_dict = {'C':6,'N':7,'O':8,'H':1,'F':9, 'Cl': 17, 'S': 16 }\n",
        "  num_atoms = len(atom_types); Cmat = np.zeros((num_atoms,num_atoms))\n",
        "  chargearray = np.zeros((num_atoms, 1))\n",
        "  chargearray = [atom_num_dict[str(symbol,'utf-8')] for symbol in atom_types]\n",
        "  for i, j in product(range(num_atoms), range(num_atoms)):\n",
        "    if i == j : Cmat[i,j] = 0.5*chargearray[i]**2.4 # Diagonal terms\n",
        "    else :\n",
        "      dist = np.linalg.norm(coords[i,:] - coords[j,:])\n",
        "      Cmat[i,j] = chargearray[i]*chargearray[j]/dist # Pair-wise repulsion\n",
        "  Cmat_eigenvalues = np.linalg.eigvals(Cmat)\n",
        "  # Cmat_eigenvalues = sorted(Cmat_eigenvalues, reverse=True) #sort (should be default)\n",
        "  pad_width = padded_size - num_atoms\n",
        "  Cmat_eigenvalues = np.pad(Cmat_eigenvalues, ((0, pad_width)), mode='constant')\n",
        "  return Cmat_eigenvalues\n",
        "\n",
        "def coulombmat_and_eigenvalues_as_vec(filename, padded_size, sort=True):\n",
        "  \"\"\"\n",
        "  returns Coulomb matrix and **sorted** Coulomb matrix eigenvalues\n",
        "  Args:\n",
        "    filename : (string) the .xyz input filename for the molecule\n",
        "    padded_size : the number of atoms in the biggest molecule to be considered (same as padded eigenvalue vector length)\n",
        "  Returns:\n",
        "    (Eigenvalues vector, Coulomb matrix vector) as Numpy arrays\n",
        "  \"\"\"\n",
        "  xyzfile = open(filename, 'r'); num_atoms_file = int(xyzfile.readline())\n",
        "  xyzfile.close(); Cmat = np.zeros((num_atoms_file,num_atoms_file))\n",
        "  chargearray = np.zeros((num_atoms_file, 1))\n",
        "  xyzmatrix = np.loadtxt(filename, skiprows=2, usecols=[1,2,3])\n",
        "  atom_symbols = np.loadtxt(filename, skiprows=2, dtype=bytes, usecols=[0])\n",
        "  atom_symbols = [symbol.decode('utf-8') for symbol in atom_symbols]\n",
        "  chargearray = [atom_num_dict[symbol] for symbol in atom_symbols]\n",
        "  for i, j in product(range(num_atoms_file), range(num_atoms_file)):\n",
        "    if i == j : Cmat[i,j]=0.5*chargearray[i]**2.4 # Diagonal terms\n",
        "    else :\n",
        "      dist=np.linalg.norm(xyzmatrix[i,:] - xyzmatrix[j,:])\n",
        "      Cmat[i,j]=chargearray[i]*chargearray[j]/dist # Pair-wise repulsion\n",
        "  Cmat_eigenvalues = np.linalg.eigvals(Cmat)\n",
        "  if (sort): Cmat_eigenvalues = sorted(Cmat_eigenvalues, reverse=True) # sort\n",
        "  Cmat_as_vec = []\n",
        "  for i, j in product(range(num_atoms_file), range(num_atoms_file)):\n",
        "    if (j>=i): Cmat_as_vec += [Cmat[i,j]]\n",
        "  pad_width = (padded_size**2 - padded_size)//2 + padded_size - ((num_atoms_file**2 - num_atoms_file)//2 + num_atoms_file)\n",
        "  Cmat_as_vec = Cmat_as_vec + [0]*pad_width; Cmat_as_vec = np.array(Cmat_as_vec)\n",
        "  pad_width = padded_size - num_atoms_file\n",
        "  Cmat_eigenvalues = np.pad(Cmat_eigenvalues, ((0, pad_width)), mode='constant')\n",
        "  return Cmat_eigenvalues, Cmat_as_vec\n",
        "\n",
        "def literal_bag_of_bonds(mol_list, predefined_bond_types=[]):\n",
        "  return sum_over_bonds(mol_list, predefined_bond_types=predefined_bond_types)\n",
        "\n",
        "def sum_over_bonds(mol_list, predefined_bond_types=[], return_names=True):\n",
        "  '''\n",
        "    \"Sum over bonds\" aka \"literal bag of bonds\" aka \"bond counting featurization\"\n",
        "    Note: Bond types are labeled according convention where the atom of the left is alphabetically less than\n",
        "    the atom on the right. For instance, 'C=O' and 'O=C' bonds are lumped together under 'C=O', and NOT 'O=C'.\n",
        "  Args:\n",
        "    mol_list : a single mol object or list/iterable containing the RDKit mol objects for all of the molecules.\n",
        "  Returns:\n",
        "    bond_types : a list of strings describing the bond types in the feature vector\n",
        "    X_LBoB : a NumPy array containing the feature vectors of shape (num_mols, num_bond_types)\n",
        "  TODO: This code could be cleaned up substantially since we are using defaultdict now.\n",
        "    <DCE 2018-06-12>\n",
        "  '''\n",
        "  if (isinstance(mol_list, list) == False): mol_list = [mol_list]\n",
        "  empty_bond_dict = defaultdict(lambda : 0); num_mols = len(mol_list)\n",
        "  if (len(predefined_bond_types) == 0 ):\n",
        "    # first pass through to enumerate all bond types in all molecules ,\n",
        "    # and set them equal to zero in the dict.\n",
        "    for i, mol in enumerate(mol_list):\n",
        "      bonds = mol.GetBonds()\n",
        "      for bond in bonds:\n",
        "        bond_start_atom = bond.GetBeginAtom().GetSymbol()\n",
        "        bond_end_atom = bond.GetEndAtom().GetSymbol()\n",
        "        bond_type = bond.GetSmarts(allBondsExplicit=True)\n",
        "        bond_atoms = [bond_start_atom, bond_end_atom]\n",
        "        if (bond_type == ''):\n",
        "          bond_type = \"-\"\n",
        "        bond_string = min(bond_atoms)+bond_type+max(bond_atoms)\n",
        "        empty_bond_dict[bond_string] = 0\n",
        "  else :\n",
        "    for bond_string in predefined_bond_types:\n",
        "      empty_bond_dict[bond_string] = 0\n",
        "  # second pass through to construct X\n",
        "  bond_types = list(empty_bond_dict.keys())\n",
        "  num_bond_types = len(bond_types)\n",
        "  X_LBoB = np.zeros([num_mols, num_bond_types])\n",
        "  for i, mol in enumerate(mol_list):\n",
        "    bonds = mol.GetBonds(); bond_dict = copy.deepcopy(empty_bond_dict)\n",
        "    for bond in bonds:\n",
        "      bond_start_atom = bond.GetBeginAtom().GetSymbol()\n",
        "      bond_end_atom = bond.GetEndAtom().GetSymbol()\n",
        "      # skip dummy atoms\n",
        "      if (bond_start_atom=='*' or bond_end_atom=='*'): pass\n",
        "      else :\n",
        "        bond_type = bond.GetSmarts(allBondsExplicit=True)\n",
        "        if (bond_type == ''): bond_type = \"-\"\n",
        "        bond_atoms = [bond_start_atom, bond_end_atom]\n",
        "        bond_string = min(bond_atoms)+bond_type+max(bond_atoms)\n",
        "        bond_dict[bond_string] += 1\n",
        "    # at the end, pick out only the relevant ones\n",
        "    X_LBoB[i,:] = [bond_dict[bond_type] for bond_type in bond_types]\n",
        "  if (return_names): return bond_types, X_LBoB\n",
        "  else : return X_LBoB\n",
        "\n",
        "def adjacency_matrix_eigenvalues(mol_list, useBO=False):\n",
        "  eigenvalue_list = []; max_length = 0\n",
        "  for mol in mol_list:\n",
        "    adj_matrix = GetAdjacencyMatrix(mol, useBO=useBO)\n",
        "    evs = list(np.linalg.eigvals(adj_matrix))\n",
        "    # evs = sorted(evs, reverse=True)\n",
        "    eigenvalue_list += [evs]; length = len(evs)\n",
        "    if (length > max_length): max_length = length\n",
        "  # zero padding\n",
        "  for i in range(len(eigenvalue_list)):\n",
        "    pad_width = max_length - len(eigenvalue_list[i])\n",
        "    eigenvalue_list[i] += [0]*pad_width\n",
        "  return np.array(eigenvalue_list)\n",
        "\n",
        "def distance_matrix_eigenvalues(mol_list, invert=False):\n",
        "  eigenvalue_list = []; max_length = 0\n",
        "  for mol in mol_list:\n",
        "    matrix = GetDistanceMatrix(mol)\n",
        "    if (invert): matrix = np.nan_to_num(np.reciprocal(matrix))\n",
        "    evs = np.linalg.eigvals(matrix); evs = np.real(evs)\n",
        "    # evs = sorted(evs, reverse=True)\n",
        "    eigenvalue_list += [evs]; length = len(evs)\n",
        "    if (length > max_length): max_length = length\n",
        "  # zero padding\n",
        "  for i in range(len(eigenvalue_list)):\n",
        "    pad_width = max_length - len(eigenvalue_list[i])\n",
        "    eigenvalue_list[i] += [0]*pad_width\n",
        "  return np.array(eigenvalue_list)\n",
        "\n",
        "def characteristic_poly(mol_list, useBO=False):\n",
        "  eigenvalue_list = []; max_length = 0\n",
        "  for mol in mol_list:\n",
        "    evs = CharacteristicPolynomial(mol, GetAdjacencyMatrix(mol, useBO=True))\n",
        "    # evs = sorted(evs, reverse=True)\n",
        "    eigenvalue_list += [list(evs)]; length = len(evs)\n",
        "    if (length > max_length): max_length = length\n",
        "  # zero padding\n",
        "  for i in range(len(eigenvalue_list)):\n",
        "    pad_width = max_length - len(eigenvalue_list[i])\n",
        "    eigenvalue_list[i] += [0]*pad_width\n",
        "  return np.array(eigenvalue_list)\n",
        "\n",
        "#-------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9_AO2CHFwk5"
      },
      "source": [
        "###**Create feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9Hn71aZVEhaX"
      },
      "outputs": [],
      "source": [
        "# Remove extension\n",
        "def b_mv(file_name):\n",
        "  try :\n",
        "    name_list = file_name.split('.')\n",
        "    for i in ['xlsx', 'txt', 'zip']:\n",
        "      if name_list[-1] == i : name_list.remove(i)\n",
        "    return '.'.join(name_list)\n",
        "  except : return file_name\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def b_xlsx(warning=False, combine=False):\n",
        "  global excel_name\n",
        "  try :\n",
        "    excel_name = b_mv(excel_name)\n",
        "    df = pd.read_excel(f'{excel_name}.xlsx')\n",
        "    # Combine every read-in sheet together.\n",
        "    if combine == True :\n",
        "      for i in range(0):\n",
        "        name = f'descriptors.xls_{i+1}'\n",
        "        sheet = pd.read_excel('descriptors.xls',sheet_name = name)\n",
        "        df = df.join(sheet)\n",
        "    # Delete column without name.\n",
        "    try : df = df.drop(columns='Unnamed: 0')\n",
        "    except : pass\n",
        "  except : print(f'ERROR: {excel_name}.xlsx is not exist.\\n'); sys.exit(0)\n",
        "  return df\n",
        "  try : df_name = df['Name']\n",
        "  except :\n",
        "    if warning == True : print(\"ERROR: the title of the column of name is not 'Name'.\")\n",
        "  try :\n",
        "    df_smiles = df['SMILES']\n",
        "    # Remove duplicate SMILES\n",
        "    df_smiles_new = []\n",
        "    for i in range(len(df_smiles)):\n",
        "      if df_smiles[i] not in df_smiles_new :\n",
        "        df_smiles_new.append(df_smiles[i])\n",
        "      else :\n",
        "        df = df.drop(labels=[i], axis=0)\n",
        "        print(f'WARNING: smiles with the name {df_name[i]} is a duplicate,')\n",
        "    if len(df_smiles) != len(df_smiles_new):\n",
        "      print(f'Originally there were {len(df_smiles)} molecules,')\n",
        "      print(f'and now there are {len(df_smiles_new)} molecules.\\n'); sys.exit(0)\n",
        "    else : print(f'No duplicate SMILES in {excel_name}.xlsx.')\n",
        "  except :\n",
        "    if warning == True : print(\"ERROR: the title of the column of SMILES is not 'SMILES'.\")\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def d_JPCL(a, keep, SoB=True, BoB=True):\n",
        "  \"\"\"\n",
        "  a: Excel name\n",
        "  keep: How many columns in front should be retained\n",
        "  SoB, BoB: Create or not...\n",
        "  \"\"\"\n",
        "  global excel_name\n",
        "  excel_name = a; num_atoms = []\n",
        "  df = b_xlsx(warning=True)\n",
        "  data = df['SMILES'].apply(MolFromSmiles).apply(AddHs)\n",
        "  # Calculate the number of atoms.\n",
        "  for mol in data : mol = AddHs(mol); num_atoms += [mol.GetNumAtoms()]\n",
        "  max_atoms = int(max(num_atoms))\n",
        "  # For Coloumb Matrix\n",
        "  while False :\n",
        "    num_mols = len(data)\n",
        "    X_Cmat_as_vec = np.zeros((num_mols, (max_atoms**2-max_atoms)//2 + max_atoms))\n",
        "    X_Cmat_eigs = np.zeros((num_mols, max_atoms))\n",
        "    X_Cmat_unsorted_eigs = np.zeros((num_mols, max_atoms))\n",
        "  filename_list = []\n",
        "  for i, refcode in enumerate(df['Name']):\n",
        "    filename = f'{os.getcwd()}/xyz/{refcode}.xyz'\n",
        "    try :\n",
        "      no_such_file = 0\n",
        "      # coulombmat_and_eigenvalues_as_vec >> returns Coulomb matrix and sorted it's eigenvalues.\n",
        "      this_Cmat_eigs, this_Cmat_as_vec = coulombmat_and_eigenvalues_as_vec(filename, max_atoms)\n",
        "      # There is 'sorted' on the top, and the default is turned off below, so it's unsorted.\n",
        "      this_Cmat_unsorted_eigs, this_Cmat_as_vec = coulombmat_and_eigenvalues_as_vec(filename, max_atoms, sort=False)\n",
        "      # Summed BoB\n",
        "      summed_BoB_feature_names, summedBoB = summed_bag_of_bonds(filename)\n",
        "      # Avoid repetitive execution.\n",
        "      filename_list += [filename]\n",
        "      # For Coloumb Matrix\n",
        "      while False : X_Cmat_eigs[i,:] = this_Cmat_eigs\n",
        "    except : no_such_file = 1\n",
        "  if no_such_file == 1 :\n",
        "    print('WARNING: upload the optimized xyz files to /xyz/ first.\\n'); sys.exit(0)\n",
        "  # Other Matrix\n",
        "  while False :\n",
        "    X_AM_eigs_BO = adjacency_matrix_eigenvalues(list(data), useBO=True)\n",
        "    X_AM_eigs = adjacency_matrix_eigenvalues(list(data))\n",
        "    X_DM_eigs = distance_matrix_eigenvalues(list(data))\n",
        "    X_CP_BO = characteristic_poly(list(data), useBO=True)\n",
        "    X_CP = characteristic_poly(list(data), useBO=False)\n",
        "  # Save feature as excel\n",
        "  df.drop(df.iloc[:,keep:], inplace=True, axis=1)\n",
        "  if SoB == True :\n",
        "    # X_LBoB >> number of bond_types, ex: H2O ['H-O'],[2]\n",
        "    bond_types, X_LBoB = literal_bag_of_bonds(list(data))\n",
        "    add_df = pd.DataFrame(X_LBoB, columns = bond_types)\n",
        "    df.join(add_df).to_excel(f'{excel_name}_SoB.xlsx')\n",
        "  if BoB == True :\n",
        "    # Number of X_BoB > n(n-1)/2 with n = max number of atoms\n",
        "    BoB_feature, X_BoB = bag_of_bonds(filename_list, verbose=False)\n",
        "    add_df = pd.DataFrame(X_BoB, columns = BoB_feature)\n",
        "    df.join(add_df).to_excel(f'{excel_name}_BoB.xlsx')\n",
        "\n",
        "#-------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWnkWDzVGka8"
      },
      "source": [
        "###**Main loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kKjhE9KqGjEm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: upload the optimized xyz files to /xyz/ first.\n",
            "\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "0",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
          ]
        }
      ],
      "source": [
        "d_JPCL('Out', 8, SoB=True, BoB=True)\n",
        "\"\"\"\n",
        "a: Excel name\n",
        "keep: How many columns in front should be retained\n",
        "SoB, BoB: Create or not...\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
